To use this API, download the code. Make sure that Flask is installed. Run the code in your terminal using “python data_aggregator_api.py”. You can then go to your preferred web browser and type in the local host specified on your terminal, with the end points ‘/50comments’, ‘/10mostusedwords’, and ‘/mostusedwords’. The first endpoint returns the first 50 comments that are made to the first 100 top stories of the moment. The second endpoint returns the 10 most used words for the first 100 comments for the top 30 stories. And the third endpoint returns the most used words in all comments, including nested comments, of the first 10 stories.

1) I think that the hardest part was optimizing the code. I am not familiar enough the aiohttp library as the majority of my api coding has been done in PHP, but with more time to look over the documentation I believe that I could improve the code.
2) The entire program could be optimized to run asynchronously. I had planned to optimize at the end using asyncio, but as I researched how to include this I came to the conclusion that asyncio should be used with aiohttp, which would require more research than I had time for. I believe that with a bit more time to research I could use this library to optimize this code.
3) To scale the API to handle thousands if not millions of calls per second, I would obviously optimize the code to run asynchronously. I would also use an API rate limit to not overwhelm the API. I might also use caching to store any data that is often retrieved so that the program does not need to constantly be retrieving from another API. Horizontally scaling on a cloud platform with multiple servers could also help.
4) In order to automate testing I would use unit testing and integration testing to make sure that the API cannot be overloaded. It would replicate the API requests with loops to make sure the program can handle the load.
3) To implement a continuous development system, I would use Github for version control and testing.
